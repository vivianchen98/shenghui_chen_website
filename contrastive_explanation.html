<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>contrastive_explanation</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v1.4.1
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Shenghui Chen</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://github.com/vivianchen98" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://www.linkedin.com/in/shenghui-chen-409805149/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://www.youtube.com/channel/UCc_vNYHqRVTKPtlTvueNe9A" class="youtube"><i class="bx bxl-youtube"></i></a>
        </div>
      </div>

      <nav class="nav-menu">
        <ul>
          <!-- <li class="active"><a href="index.html"><i class="bx bx-home"></i> <span>Home</span></a></li> -->
          <!-- <li><a href="#about"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="#resume"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="#publication"><i class="bx bx-book-content"></i> Publication</a></li> -->
          <li><a href="javascript:history.back()"><i class="bx bx-book-content"></i> Go back</a></li>
          <!-- <li><a href="#activities"><i class="bx bx-server"></i> Activities</a></li>
          <li><a href="#contact"><i class="bx bx-envelope"></i> Contact</a></li> -->

        </ul>
      </nav><!-- .nav-menu -->
      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

    </div>
  </header>
  <!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <!-- <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Portfoio Details</h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>Portfoio Details</li>
          </ol>
        </div>

      </div>
    </section> -->
    <!-- End Breadcrumbs -->

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">

        <!-- <div class="portfolio-details-container"> -->

          <!-- <div class="owl-carousel portfolio-details-carousel">
            <img src="assets/img/portfolio/load_balancing.png" class="img-fluid" alt="">
            <img src="assets/img/portfolio-details-2.jpg" class="img-fluid" alt="">
            <img src="assets/img/portfolio-details-3.jpg" class="img-fluid" alt="">
          </div> -->

          <!-- <div class="portfolio-info">
            <h3>Project information</h3>
            <ul>
              <li><strong>Category</strong>: Research <strong>Timeline</strong>: 01 March, 2020 <strong>Keywords</strong>: Formal methods</li>
              <li><strong>Timeline</strong>: 01 March, 2020</li>
              <li><strong>Keywords</strong>: Formal methods</li>
              <li><strong>Project URL</strong>: <a href="#">www.example.com</a></li>
            </ul>
          </div> -->

        <!-- </div> -->

        <div class="portfolio-description">
          <h1 style="text-align:center;">Towards Transparent Robotic Planning via Contrastive Explanations</h1>
          <p style="text-align:center; background-color:LemonChiffon"><strong>Category</strong>: Research <strong>Timeline</strong>: Aug, 2019 - Mar, 2020 <strong>Keywords</strong>: Formal methods, xAI</p>

          <p><strong>Shenghui Chen</strong>, Kayla Boggess, and Lu Feng.
            <a href="https://arxiv.org/abs/2003.07425">Towards Transparent Robotic Planning via Contrastive Explanations.</a>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Mar 2020</em></p>

          <p>
            <strong>Problem</strong>
            <br>Common “black-box” AI approach gives users little understanding of how a decision is made, often leading to misunderstanding, mistrust, and misuse.
            Many work in Explainable AI (XAI) focused on the building of simplified interpretable models as approximations of complex decision making functions.
            However, Few start from the social science theories of explanations by first asking “what do users want?”
          </p>

          <p>
            <strong>Contribution</strong>
          </p>
          <ul>
            <li>A formalized notion of contrastive explanations (selective, constrictive, responsible)</li>
            <li>Methods to automatically generate contrastive explanations </li>
            <li>A user study with 100 participants to investigate user understanding, trust and preference about contrastive explanations</li>
          </ul>

          <p>
            <strong>Motivating example</strong>
            <!-- <figure class="figure"> -->
              <img src="assets/img/contrastive_explanation/labeled_grid.jpg" class="rounded float-right" alt="Motivating example" width="300">
              <!-- <figcaption class="figure-caption text-center">Grid map for motivating example</figcaption>
            </figure> -->
            Consider the route planning for a robot navigating in a grid map.
            <br>There are three possible routes from the start (S) to the destination (D) highlighted in different colors.
            The robot may take different routes, depending on the trade-offs of different objectives
            (e.g., minimizing the total route distance to destination, minimizing the risk of colliding with pedestrians or cyclists).
            <br> A naive way to explain a route is to generate a sentence for each action the robot takes at every state using a structured language template
            (e.g., "We move east at grid 10."), and then concatenate these sentences following the sequence of states in the route.
            <br>However, it would be tedious if not infeasible to explain the robotic action in every state following the route,
            especially for large MDP models with hundreds of thousands of states.
            Therefore, we select a handful of <em>critical states</em> and only explain actions on those states.
            <br>In addition to explain what action is taken in a state, we also explain why the action is taken by comparing it to alternative actions in terms of <em>constrictiveness</em>
            (e.g., "We move east at grid 10 because it leads to the most flexible future route.") and <em>responsibility</em>
            (e.g., "We move east at grid 10 because it leads to the shortest route.").
          </p>

          <p>
            <strong>Contrastive Explanation</strong>
            <br>In this paper, we present methods to compute contrastive explanations with three key factors
            (<em>selectiveness, constrictiveness and responsibility</em>) for robotic planning based on Markov decision processes,
            drawing on insights from the social sciences.

            <ul>
              <li><strong>Seletiveness</strong>
                <br> we define the notion of <em>critical states</em> in an MDP model and only explain actions in those states.
                Intuitively, a critical state is where the choice of actions would greatly affect the MDP policies and their performance.
              </li>
              <li><strong>Constrictiveness</strong>
                <br>In social sciences, a decision is said to be more "constrictive" if choosing it causes less possible future decisions.
                In this paper, we interpret <em>constrictiveness</em> as a measurement of how much an action would affect the flexibility
                in terms of the number of critical decision points left in the future route.
                Intuitively, more decision points lead to more flexibility for the robot to reroute,
                hence it is considered less constrictive and is preferred as time passes.
              </li>
              <li><strong>Responsiblity</strong>
                <br>In social sciences, an action is said to be more "responsible" if it changes the outcome more by removing that action from the current chosen path.
                Humans tend to be more interested in actions that hold a higher responsibility as it measures how much influence an action has over the final outcome.
                In this paper, we interpret <em>responsibility</em> as the measurement of an action's relative impact on the MDP property value compared with other actions enabled in the same state.
              </li>
            </ul>

          </p>

          <p>
            <strong>Generated explanations</strong>
            <br>Multiple performance properties are checked in PRISM model checker

            <div class="text-center">
              <img src="assets/img/contrastive_explanation/Table.png" class="rounded" alt="Generated Explanations" width="700">
              <figcaption class="figure-caption text-center">Generated Explanations</figcaption>
            </div>
          </p>

          <p>
            <strong>User study</strong>
          </p>
          <p><em>Experiments</em></p>
          <ul>
            <li>100 participants on Amazon Mechanical Turk </li>
            <li>Independent: route presented and explanation type</li>
            <li>Dependent: understanding, trust, preference, time</li>
            <li>Hypothesis: contrastive explanation will increase understanding, trust, and be preferred by users</li>
          </ul>
          <figure class="figure">
            <img src="assets/img/contrastive_explanation/Understanding.png" class="figure-img img-fluid rounded" alt="Understanding" width="500">
            <figcaption class="figure-caption text-center">Understanding</figcaption>
          </figure>
          <figure class="figure">
            <img src="assets/img/contrastive_explanation/Trust.png" class="figure-img img-fluid rounded" alt="Understanding" width="500">
            <figcaption class="figure-caption text-center">Trust</figcaption>
          </figure>

          <p><em>Conclusions</em></p>
          <ul>
            <li>Users understand responsibility-based  and constrictive-based explanation more than their naive counterparts;</li>
            <li>Contrastive explanations can reduce the average time a user spent (cognitive burden);</li>
            <li>Users trust contrastive explanations relatively well;</li>
            <li>Users show a diverse set of preferences regarding explanations.</li>
          </ul>
        </div>
      </div>
      <div class="embed-responsive embed-responsive-16by9">
        <iframe width="500px" height="281.25px" src="https://www.youtube.com/embed/CEtH9a8E7do" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <a href="https://bootstrapmade.com/"><strong><span>Shenghui Chen</span></strong>
      </div>

    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
